# データ処理パイプライン仕様書

以下は **「実装寄りのコード」から"仕様書レベル"へ抽象度を引き上げて整理した**
データ前処理パイプラインの仕様まとめです。
再実装する際は本ドキュメントを単一ソース・オブ・トゥルースとして参照してください。

---

## 目次

1. [全体像 — 3-Layer アーキテクチャ](#0-全体像--3-layer-アーキテクチャ)
2. [Silver Layer — データクリーニング](#1-silver-layer--データクリーニング)
3. [外れ値処理](#2-外れ値処理)
4. [Gold Layer — 特徴量エンジニアリング](#3-gold-layer--特徴量エンジニアリング)
5. [エンコーディング & スケーリング](#4-エンコーディング--スケーリング)
6. [アーティファクト管理](#5-アーティファクト管理)
7. [データフロー](#6-データフロー)
8. [再現手順](#7-再現手順)
9. [リファクタリング版仕様（YAML）](#8-リファクタリング版仕様yaml)

---

## 0. 全体像 — 3-Layer アーキテクチャ

| レイヤ        | 目的                   | 主な格納場所                                                    | 主キー              | 出力先       |
| ---------- | -------------------- | --------------------------------------------------------- | ---------------- | --------- |
| **Bronze** | "ありのまま"の取り込み。スキーマ最小  | `bronze_raw_house_data`                                   | `id`             | Silver    |
| **Silver** | クリーニング & 型そろえ & 初期派生 | `silver_house_data`                                       | `id`             | Gold／ML   |
| **Gold**   | モデル学習に必要な高レベル特徴量     | `ft_house_ml` (dbt) または `v_house_analytics` (DuckDB view) | `transaction_id` | ML パイプライン |

---

## 1. Silver Layer — データクリーニング

### 1.1 基本データクリーニング

| 項目                       | 処理仕様              | NULL 許可 | 備考      |
| ------------------------ | ----------------- | ------- | ------- |
| `price`                  | `>0` でなければ `NULL` | ❌       | 単位: USD |
| `sqft`                   | `>0` でなければ `NULL` | ❌       |         |
| `bedrooms` / `bathrooms` | `>0` でなければ `NULL` | ❌       |         |
| `year_built`             | 1900 〜 現在年        | ❌       |         |
| `location` / `condition` | 先頭後尾空白除去→大文字化     | ❌       |         |

### 1.2 派生カラム

| カラム              | 算出式                         |
| ---------------- | --------------------------- |
| `price_per_sqft` | `price / sqft`              |
| `house_age`      | `current_year - year_built` |
| `bed_bath_ratio` | `bedrooms / bathrooms`      |

### 1.3 品質フラグ

| フラグ                  | 意味                | 算出条件                            |
| -------------------- | ----------------- | ------------------------------- |
| `is_price_outlier`   | 平米単価が常識外か         | `price_per_sqft < 50 OR > 1000` |
| `is_age_outlier`     | 築年数 0 未満 or 100 超 | 同上                              |
| `is_complete_record` | "学習可" か           | 必須列がすべて NOT NULL                |

---

## 2. 外れ値処理

### 2.1 統計的外れ値検出（IQR法）
- **対象**: `price`, `sqft` など数値列
- **方法**: IQR × 1.5 による検出

### 2.2 ドメイン知識に基づく外れ値検出
- **対象**: 上表の `is_*_outlier` フラグ
- **取り扱い**: Silver ➡ Gold エクスポート時に **除外**（ソフトデリート相当）

### 2.3 完全レコードの識別
- **条件**: 必須列がすべて NOT NULL
- **用途**: ML 学習対象の判定

---

## 3. Gold Layer — 特徴量エンジニアリング

### 3.1 対数変換
- **対象**: `price`, `sqft`
- **方法**: `log1p` で 0 値対応
- **出力**: `log_price`, `log_sqft`

### 3.2 多項式特徴量
- **次数**: 2〜3次
- **対象**: `sqft`, `price_per_sqft`
- **出力**: `sqft_squared`, `price_per_sqft_squared`, `sqft_cubed`

### 3.3 交互作用特徴量
- **方法**: 掛け算
- **例**: `price_bedrooms_interaction` など 6 種

### 3.4 カテゴリカル特徴量の作成
- **方法**: 四分位や閾値で 0/1
- **例**: `is_old_house`, `is_large_house`, `is_expensive`

### 3.5 位置ベース特徴量
- **方法**: 集約 + ランク
- **例**: `location_avg_price`, `price_vs_location_avg`, `location_price_rank`

### 3.6 条件スコアの数値化
- **対象**: `condition`
- **マッピング**: Poor=1 … Excellent=4

---

## 4. エンコーディング & スケーリング

### 4.1 欠損補完
- **数値**: mean
- **カテゴリ**: most_frequent
- **ライブラリ**: `SimpleImputer`

### 4.2 ワンホットエンコーディング
- **対象**: `location`, `condition`
- **設定**: drop first
- **ライブラリ**: `OneHotEncoder`
- **保存物**: `location_mapping.pkl`, `condition_mapping.pkl`

### 4.3 特徴量スケーリング
- **方法**: StandardScaler
- **出力**: `_scaled` サフィックス列を追加
- **保存物**: `feature_scaler.pkl`

---

## 5. アーティファクト管理

| ファイル                    | 格納先 (`target/preprocessing_artifacts`) | 内容 |
| ----------------------- | -------------------------------------- | -- |
| `feature_names.pkl`     | 使用した全特徴量名リスト                           |    |
| `data_stats.pkl`        | mean / std / min / max / median        |    |
| `location_mapping.pkl`  | 出現回数などの辞書                              |    |
| `condition_mapping.pkl` | 同上                                     |    |
| `feature_scaler.pkl`    | 学習済み `StandardScaler` インスタンス           |    |

---

## 6. データフロー

```mermaid
flowchart LR
    A[Bronze CSV取込] --> B[Silver Cleaning]
    B -->|品質フラグでフィルタ| C[Gold Feature Engineering]
    C --> D[One-Hot & Scale]
    D --> E[ML Training]
    E --> F[(MLflow / Artifacts)]
```

---

## 7. 再現手順（ローカル）

### 7.1 原データ配置
```bash
# データを配置
src/data/raw/house_data.csv
```

### 7.2 DWH 作成
```bash
python scripts/create_dwh.py
```

### 7.3 モデル前処理まで一気に生成
```bash
python src/ml/pipeline/train_pipeline.py \
       --duckdb src/data/warehouse/duckdb/data/house_price.duckdb
# → target/preprocessing_artifacts/ に pkl 群が出来ればOK
```

---

## 8. リファクタリング版仕様（YAML）

### 8.1 概要

**ねらい**
1. 仕様を *機械可読 (YAML)* + *人可読 (本文)* の二層で定義し直す
2. "どの値をどう検証・変換するか" を **列ごと** に宣言的に記述
3. Silver／Gold の責務境界を **1ファイル＝1レイヤ** で完全分離

### 8.2 ディレクトリ & ファイル粒度

```
dataprep_spec/                    # ← ここが単一ソース・オブ・トゥルース
 ├─ bronze.yml                    # 取込スキーマ（型だけ宣言、ロジックなし）
 ├─ silver.yml                    # クリーニング & 初期派生  ※今回の中心
 ├─ gold.yml                      # 特徴量エンジニアリング
 ├─ encoding_scaling.yml          # One-Hot / StandardScaler 設定
 └─ artifacts.yml                 # 保存すべき pkl 一覧
```

実装側は **YAML→Dict → 汎用エンジン** で適用するだけ。
*仕様変更＝YAML編集* でコードは原則触らない設計にします。

### 8.3 `silver.yml` — 列定義 & ルール例

```yaml
columns:
  price:
    type: float
    nullable: false
    rules:
      - { op: gt, value: 0 }                 # >0
  sqft:
    type: float
    nullable: false
    rules:
      - { op: gt, value: 0 }
  bedrooms:
    type: int
    nullable: false
    rules:
      - { op: gt, value: 0 }
  bathrooms:
    type: int
    nullable: false
    rules:
      - { op: gt, value: 0 }
  year_built:
    type: int
    nullable: false
    rules:
      - { op: between, min: 1900, max: today }
  location:
    type: str
    nullable: false
    transform: [ strip, upper ]
  condition:
    type: str
    nullable: false
    transform: [ strip, upper ]

derived:
  price_per_sqft: "price / sqft"
  house_age: "current_year - year_built"
  bed_bath_ratio: "bedrooms / bathrooms"

flags:
  is_price_outlier:
    expr: "price_per_sqft < 50 or price_per_sqft > 1000"
  is_age_outlier:
    expr: "house_age < 0 or house_age > 100"
  is_complete_record:
    expr: |
      price is not null and sqft is not null and
      bedrooms is not null and bathrooms is not null and
      year_built is not null and location is not null and
      condition is not null
```

**ポイント**
- **rules** は配列にして ½ 行でも複数条件を追加可
- `transform` は簡易 DSL。実装側で `str.strip().upper()` の関数連結に落とす
- `expr` は Jinja2 / pandas‐eval 等で実行

### 8.4 `gold.yml` — 特徴量カタログ

```yaml
log_transform:
  - price
  - sqft

polynomial:
  degree_2:
    - sqft
    - price_per_sqft
  degree_3:
    - sqft

interactions:
  - { left: price,      right: bedrooms,   name: price_bedrooms_interaction }
  - { left: price,      right: bathrooms,  name: price_bathrooms_interaction }
  - { left: sqft,       right: bedrooms,   name: sqft_bedrooms_interaction }
  - { left: sqft,       right: bathrooms,  name: sqft_bathrooms_interaction }
  - { left: price,      right: sqft,       name: price_sqft_ratio,  op: div }

domain_buckets:
  house_age:
    bins: [0, 10, 50, inf]
    labels: [is_new_house, is_medium_age, is_old_house]
  sqft:
    quantiles: [0.25, 0.75]
    labels: [is_small_house, is_large_house]
  price:
    quantiles: [0.25, 0.75]
    labels: [is_affordable, is_expensive]

location_features:
  - location_avg_price
  - price_vs_location_avg
  - location_price_rank

ordinal_encode:
  condition:
    mapping: { POOR: 1, FAIR: 2, GOOD: 3, EXCELLENT: 4 }
```

### 8.5 `encoding_scaling.yml`

```yaml
impute:
  numeric: mean
  categorical: most_frequent

onehot:
  columns: [ location, condition ]
  drop_first: true

scaler:
  type: standard
  suffix: _scaled
```

### 8.6 `artifacts.yml`

```yaml
save:
  - feature_names.pkl
  - data_stats.pkl
  - location_mapping.pkl
  - condition_mapping.pkl
  - feature_scaler.pkl
dir: target/preprocessing_artifacts
```

### 8.7 仕様⇄実装マッピング早見表

| YAML セクション             | Python モジュール (参考)        | 出力テーブル/ビュー                          |
| ---------------------- | ------------------------ | ----------------------------------- |
| `silver.yml: columns`  | `dataprep.silver.clean`  | `silver_house_data`                 |
| `silver.yml: derived`  | `dataprep.silver.derive` | 同上 (追加列)                            |
| `silver.yml: flags`    | `dataprep.silver.flags`  | 同上 (追加列)                            |
| `gold.yml:*`           | `dataprep.gold.*`        | `ft_house_ml` / `v_house_analytics` |
| `encoding_scaling.yml` | `dataprep.encoders.*`    | ML 入力 DataFrame                     |
| `artifacts.yml`        | `dataprep.artifacts.*`   | `target/preprocessing_artifacts`    |

### 8.8 メリット

1. **宣言的** – 仕様変更は YAML 修正のみ。テストは YAML → 小データで即検証。
2. **追跡性** – Git diff が "値 or 式の変更" に限定 → コードレビューが容易。
3. **再現性** – パイプラインは *YAML + ソース CSV* があればどこでも同一結果。

### 8.9 次アクション

1. `dataprep_spec/` をリポジトリ直下に追加
2. 既存 Python を **YAML 消費型ユーティリティ** に置換
3. CI で `yamllint` & スキーマバリデーションを追加（仕様漏れ防止）

---

## まとめ

* **Silver** で「欠損・型・外れ値」を解決し **Gold** で「予測に効く特徴量」を付加
* すべての派生カラム・フラグは **表形式で仕様化** したので再実装やレビューが容易
* 推論時は Saved Artifacts をロードすれば **訓練時と同じ前処理** が必ず再現可能

> **このドキュメントをベースに、コードや CI のパスを追従させれば "重要ファイル紛失" リスクはほぼゼロになります。**

> **このリファクタリング仕様に沿えば、ドキュメント＝実装＝CI が完全同期し、
> "重要ファイル紛失" や "仕様とコードの乖離" を未然に防げます。**