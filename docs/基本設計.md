# 基本設計ドキュメント

## 目次
1. [プロジェクト概要](#プロジェクト概要)
2. [プロジェクト構成](#プロジェクト構成)
3. [CI/CD方針](#cicd方針)
4. [データフロー概要](#データフロー概要)
5. [Medallion Architecture](#medallion-architecture)
6. [データ品質管理](#データ品質管理)
7. [技術スタック](#技術スタック)
8. [機械学習アルゴリズム](#機械学習アルゴリズム)
9. [運用メモ](#運用メモ)

---

## プロジェクト概要

このプロジェクトは、**Medallion Architecture（メダリオン・アーキテクチャ）**に基づいて構築された3層のデータ処理パイプラインです。Kaggle対策を目的としており、生データからMLモデル用の高品質な特徴量まで、段階的かつ追跡可能なデータ処理を実現しています。

---

## プロジェクト構成

```
プロジェクトルート: /home/wsl/dev/mlops/simple-dwh-mlops
設定ファイル     : /home/wsl/dev/mlops/simple-dwh-mlops/configs

環境：Kaggle対策なのでdevelopmentのみ
```

---

## CI/CD方針

* **開発スピード最優先** のため、CI での *lint チェックは実施しない*
* Kaggle対策なのでサービス API UI無し
* CIでMLopsをしっかりチェックする

---

## データフロー概要

1. **Raw Data** を **DuckDB** に取り込み
2. 取り込んだ **raw データ**を以下の処理を経て **dbt** で各レイヤ（Bronze → Silver → Gold）を生成
   * 前処理（クリーニング）
   * ワンホットエンコーディング
   * 外れ値処理

---

## Medallion Architecture

### アーキテクチャ概要

```
Bronze Layer（生データ）
   → Silver Layer（クリーンデータ）
      → Gold Layer（ML 用特徴量）
```

### 各レイヤの役割と処理内容

#### **Bronze Layer（ブロンズ層）**

| 項目     | 内容                                        |
| ------ | ----------------------------------------- |
| 目的     | 生データの保存・参照                                |
| 主な SQL | `models/bronze/bronze_raw_house_data.sql` |
| 処理     | 取り込みのみ（変換なし）、テーブルにマテリアライズ                 |

**処理内容**:
- Pythonのデータ取り込みプロセスで作成された生データを参照
- データの変換や加工は行わず、そのまま保持
- テーブル形式でマテリアライズ

#### **Silver Layer（シルバー層）**

| 項目     | 内容                                                                                                                                                                    |
| ------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 目的     | データクリーニングと標準化                                                                                                                                                         |
| 主な SQL | `models/silver/silver_house_data.sql`                                                                                                                                 |
| 主な処理   | <ul><li>数値列の妥当性チェック（価格・面積・部屋数など）</li><li>建設年を 1900〜現在年の範囲に制限</li><li>文字列列のトリム＆大文字化</li><li>派生フィールド計算（平米単価・築年数・寝室/浴室比率）</li><li>品質フラグ付与（完全レコード／価格外れ値／築年数外れ値）</li></ul> |

**処理内容**:
```sql
-- データ検証とクリーニング
- 価格、面積、部屋数などの数値データの妥当性チェック
- 建設年（1900年〜現在）の範囲チェック
- 位置情報とコンディションの標準化（大文字変換、トリム）

-- 派生フィールドの計算
- price_per_sqft（平米単価）
- house_age（築年数）
- bed_bath_ratio（寝室・浴室比率）

-- データ品質フラグ
- is_complete_record（完全レコードフラグ）
- is_price_outlier（価格外れ値フラグ）
- is_age_outlier（築年数外れ値フラグ）
```

#### **Gold Layer（ゴールド層）**

| 項目        | 内容                                                                                                                                                                                                        |
| --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 目的        | ML モデル学習用の高次特徴量エンジニアリング                                                                                                                                                                                   |
| 主な Python | `models/gold/ft_house_ml.py`                                                                                                                                                                              |
| 主な処理      | <ul><li>対数変換、ポリノミアル、交互作用、カテゴリ階級化</li><li>位置情報ベースの集約特徴量</li><li>コンディションスコアの数値化</li><li>エンコーディング（Label/One-Hot）とスケーリング</li><li>前処理アーティファクト保存（LabelEncoder, StandardScaler など）</li><li>相関ベースの特徴量選択</li></ul> |

**処理内容**:

##### **特徴量エンジニアリング**:
```python
# 対数変換（歪んだデータの正規化）
- log_price, log_sqft

# 多項式特徴量
- sqft_squared, price_per_sqft_squared

# 交互作用特徴量
- price_bedrooms_interaction
- price_bathrooms_interaction
- sqft_bedrooms_interaction

# カテゴリカル特徴量
- is_old_house, is_new_house
- is_large_house, is_expensive

# 位置ベース特徴量
- location_avg_price（地域平均価格）
- price_vs_location_avg（地域平均との比較）

# コンディションスコア
- condition_score（数値化）
```

##### **特徴量エンコーディング**:
```python
# ラベルエンコーディング
- location_encoded（位置情報の数値化）

# 前処理アーティファクトの保存
- LabelEncoder, StandardScaler
- 特徴量名、データ統計情報
```

##### **特徴量スケーリング**:
```python
# StandardScalerによる標準化
- 数値特徴量の標準化（平均0、分散1）
- スケール済み特徴量の追加
```

##### **特徴量選択**:
```python
# 相関分析による重要特徴量の選択
- ターゲット変数との相関が高い特徴量を選択
- 必須特徴量の確保
- 最終的に10-15個の特徴量に絞り込み
```

---

## データ品質管理

### dbtテスト
- `not_null`：必須列の NULL チェック
- `unique`：主キーの重複チェック
- 各層で適切なテストを定義

### 品質フラグ
- `is_complete_record`：完全レコードの識別
- `is_price_outlier`：価格外れ値の検出とフラグ付け
- `is_age_outlier`：築年数外れ値の検出とフラグ付け

---

## 技術スタック

| 項目               | 理由 / 効果                                       |
| ---------------- | --------------------------------------------- |
| **DuckDB**       | 軽量・高速。Python との親和性が高い                         |
| **dbt**          | SQL モデルの依存関係管理とテストを自動化                        |
| **scikit-learn** | 複雑な特徴量エンジニアリングや前処理の再利用が容易                     |
| **スキーマ分離**       | `bronze` / `silver` / `gold` ごとのアクセス制御・可観測性向上 |

### 技術的特徴

#### **DuckDB統合**:
- 軽量な分析用データベース
- Pythonとの親和性が高い
- 高速なクエリ実行

#### **Pythonモデル**:
- 複雑な特徴量エンジニアリングをPythonで実装
- scikit-learnライブラリの活用
- 前処理アーティファクトの保存

#### **スキーマ分離**:
- bronze, silver, goldスキーマで層を分離
- データの流れを明確化
- アクセス制御の実装が容易

---

## 機械学習アルゴリズム（実装済み）

* **ランダムフォレスト**
* **XGBoost**
* **アンサンブル**／**スタッキング**
* （ディープラーニングは未使用）

---

## 運用メモ

> もしさらなる削減・簡素化が必要であれば、**dbt Silver まで** で止めて
> Gold の特徴量生成は Python 側で一本化するなど、段階的にスリム化が可能です。

このアーキテクチャにより、生データからMLモデル用の高品質な特徴量まで、段階的かつ追跡可能なデータ処理パイプラインを実現しています。

