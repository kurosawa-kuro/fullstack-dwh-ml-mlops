## “汎用データ前処理テンプレート”設計書

> **どのドメインでも流用できる様に** ― 手順・命名規約・保存アーティファクトを **抽象化** しました。
> （数字はユーザ提示の章立てと対応）

---

### 1. 派生フィールドの計算  *(Derived Features)*

| 種別         | 代表パターン                          | 推奨命名                                    | NULL 規則         | 備考           |
| ---------- | ------------------------------- | --------------------------------------- | --------------- | ------------ |
| **比率**     | `price / sqft`                  | `<numer>/<denom> → {numer}_per_{denom}` | 除算不可 ➜ `NULL`   | 正規化 & 単位差吸収  |
| **差分**     | `event_time – first_event_time` | `delta_<from>_<to>`                     | 欠損片側あり ➜ `NULL` | 滞在・経過時間      |
| **バケット**   | `age > 50`                      | `is_old_*`                              | BOOL (0/1)      | 四分位, ドメイン閾値で |
| **順位/ランク** | `rank() over (…)`               | `<col>_rank_pct`                        | 0–1 DOUBLE      | 分布位置を保持      |
| **日時分解**   | `order_dt` → Y/M/D              | `year_*, month_*, day_*`                | 0 代入不可          | 季節性・周期性      |

---

### 2. 外れ値検出と処理  *(Outlier Handling)*

| ステップ           | メソッド              | 推奨ロジック                                        | ハンドリング                       |
| -------------- | ----------------- | --------------------------------------------- | ---------------------------- |
| **2.1 統計的**    | IQR×1.5 / z-score | `lower = Q1 – k·IQR`<br>`upper = Q3 + k·IQR`  | *除外* or *Winsorize*（閾値で切り詰め） |
| **2.2 ドメイン**   | ビジネスルール           | 例) `age >100`, `price_per_sqft <50`           | フラグ列 `is_<col>_outlier` 付与   |
| **2.3 完全レコード** | **品質マスク**         | `is_complete_record = every(col IS NOT NULL)` | Gold 以降で **WHERE** 句に使用      |

---

### 3. ワンホットエンコーディング  *(Categorical Encoding)*

| ポイント        | 推奨値                                                   |
| ----------- | ----------------------------------------------------- |
| **カラム選定**   | `unique_count ≤ 50` を目安（高過ぎる場合は **ターゲットエンコーディング** 検討） |
| **未知カテゴリ**  | `handle_unknown='ignore'` もしくはダミー列 `unknown_FLAG`     |
| **多重共線性**   | `drop='first'`（最初のダミー削除）                              |
| **手動エンコード** | `pd.get_dummies(drop_first=True)` を統一ラッパー関数化          |

---

### 4. 特徴量エンジニアリング  *(Gold Layer)*

| #   | カテゴリ         | 典型列例               | 実装指針                                               |
| --- | ------------ | ------------------ | -------------------------------------------------- |
| 4.1 | **対数変換**     | 右裾重い金額・面積          | `log1p()` で 0 値可                                   |
| 4.2 | **多項式**      | 面積², 単価³           | `PolynomialFeatures(degree≤3, include_bias=False)` |
| 4.3 | **交互作用**     | `price × bedrooms` | 重要組合せのみ事前設計                                        |
| 4.4 | **カテゴリバケット** | `is_large_house` 等 | 四分位・業界閾値                                           |
| 4.5 | **位置派生**     | 地域平均価格, ランク        | Window 集計 (`avg`, `rank`)                          |
| 4.6 | **順序エンコード**  | 品質スコア              | Dict マッピング（YAML 管理）                                |

---

### 5. 特徴量スケーリング  *(Scaling)*

| フェーズ         | 手法                                  | 適用列      | 保存物                  |
| ------------ | ----------------------------------- | -------- | -------------------- |
| **欠損補完**     | `SimpleImputer(mean/most_frequent)` | 全数値／カテゴリ | –                    |
| **標準化**      | `StandardScaler`                    | 数値列      | `feature_scaler.pkl` |
| **正則化 (任意)** | `MinMaxScaler`                      | モデル依存で   | `minmax_scaler.pkl`  |

---

### 6. 前処理アーティファクト保存  *(Reproducibility)*

| ファイル                | 内容                                        | フォーマット |
| ------------------- | ----------------------------------------- | ------ |
| `feature_names.pkl` | トレーニング列順リスト                               | Pickle |
| `data_stats.pkl`    | mean / std / min / max / median           | Pickle |
| `*_mapping.pkl`     | カテゴリ→整数/頻度辞書                              | Pickle |
| `*_scaler.pkl`      | 学習済 Scikit-Learn オブジェクト                   | Pickle |
| **メタ**              | `schema_hash.txt`, `pipeline_version.txt` | Text   |

> **ルール** : *「学習時に生成したものは必ず保存 → 推論時に再利用」*
> パスは `target/preprocessing_artifacts/{YYYYMMDD_HHMMSS}/`.

---

### 7. 最小コード・テンプレ（抜粋）

```python
# ====== outlier mask (IQR) ======
def iqr_mask(s, k=1.5):
    q1, q3 = s.quantile([0.25, 0.75])
    iqr = q3 - q1
    return (s < q1 - k*iqr) | (s > q3 + k*iqr)

# ====== encoder / scaler pipeline ======
preprocessor = ColumnTransformer(
    transformers=[
        ("num", Pipeline([
            ("imputer", SimpleImputer(strategy="mean")),
            ("scaler", StandardScaler())
        ]), num_cols),
        ("cat", Pipeline([
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("ohe", OneHotEncoder(handle_unknown="ignore", drop="first", sparse_output=False))
        ]), cat_cols)
    ],
    remainder="drop"
)
```

---

## 使い方フロー

1. **Silver** で QC ＆派生基礎列 → `is_*_outlier`, `is_complete_record`
2. **Gold** で **4.x** の高次特徴量を追加
3. `preprocessor.fit(df_gold)` → Pickle 保存
4. モデル学習／MLflow ログ

---

### 📌 ベストプラクティスまとめ

* **“関数単位”** で処理を切り、ユニットテストを書く
* ハイパラ (IQR 倍数・多項式次数など) は **YAML** で外出し
* 変換後列は `<orig>_<suffix>` 命名で由来を明確に
* アーティファクトは **日時バージョン** で衝突防止
* パイプラインの **hash** をモデルにタグ付けし、データ drift を検知

これで「よくある前処理パーツ」が**一枚の仕様**で見渡せ、
誰でも同じルールで再実装・レビューできます。
